# -*- coding: utf-8 -*-
"""SBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/iisc-ts-group6/capstone/blob/main/SBERT.ipynb
"""

!pip install sentence-transformers pandas openpyxl datasets

# Import necessary libraries
import pandas as pd
from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation
from torch.utils.data import DataLoader, Dataset, random_split
from sklearn.model_selection import train_test_split
import re
import numpy as np

# Load the Excel file
file_path = '/content/master_sheet.xlsx'
df = pd.read_excel(file_path)

import re
# Define a text cleaning function
def clean_text(text):
    # Remove excess newline characters
    text = re.sub(r'\s+', ' ', text)
    # Convert to lowercase
    text = text.lower()
    # Remove special characters
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    return text

# Clean the data to ensure no NaN values
df.fillna("", inplace=True)

df.head()
len(df)

# Apply text cleaning to each column
df['question'] = df['Question'].apply(clean_text)
df['answer'] = df['Answer'].apply(clean_text)
df['D1'] = df['D1'].apply(clean_text)
df['D2'] = df['D2'].apply(clean_text)
df['D3'] = df['D3'].apply(clean_text)

# Prepare training examples
train_examples = []

# Iterate over each row to create positive and negative examples
for index, row in df.iterrows():
    question = row['Question']
    answer = row['Answer']
    distractors = [row['D1'], row['D2'], row['D3']]

    # Positive example (question, correct answer)
    train_examples.append(InputExample(texts=[question, answer], label=1.0))

    # Negative examples (question, distractors)
    for distractor in distractors:
        train_examples.append(InputExample(texts=[question, distractor], label=0.0))

# Split the dataset into training and testing sets
train_size = int(0.8 * len(train_examples))
test_size = len(train_examples) - train_size
train_dataset, test_dataset = random_split(train_examples, [train_size, test_size])

# Convert the training examples into a DataLoader
train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)
test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=16)

# Load pre-trained SBERT model
model = SentenceTransformer('all-mpnet-base-v2')

# Define the loss function for training
train_loss = losses.CosineSimilarityLoss(model)

!pip install transformers[torch] accelerate -U

import torch
# specify GPU
device = torch.device("cuda")

# Train the SBERT model
model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)

# Evaluate the model on the test set
evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test_dataset, name='test')
model.evaluate(evaluator)

# Example sentences to compute embeddings and evaluate similarity on real-time data
real_time_sentences = ["The quick brown fox jumps over the lazy dog", "A fast, brown fox leaps over a lazy dog"]

# Clean the real-time sentences
real_time_sentences = [clean_text(sentence) for sentence in real_time_sentences]

# Compute sentence embeddings
real_time_embeddings = model.encode(real_time_sentences)

# Function to compute cosine similarity
def cosine_similarity(emb1, emb2):
    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

# Compute and print cosine similarity between real-time sentence pairs
for i in range(len(real_time_sentences)):
    for j in range(i+1, len(real_time_sentences)):
        sim = cosine_similarity(real_time_embeddings[i], real_time_embeddings[j])
        print(f"Similarity between '{real_time_sentences[i]}' and '{real_time_sentences[j]}': {sim:.4f}")

# Function to test the model on new inputs
def test_similarity(question, correct_answer, student_answer):
    # Clean the input text
    question = clean_text(question)
    correct_answer = clean_text(correct_answer)
    student_answer = clean_text(student_answer)

    # Compute embeddings
    embeddings = model.encode([question, correct_answer, student_answer])

    # Compute similarity score between correct answer and student answer
    sim_score = cosine_similarity(embeddings[1], embeddings[2])

    return sim_score

!pip install openai

import os
f = open('/content/openapi_key_team.txt')
api_key = f.read()
os.environ['OPENAI_API_KEY'] = api_key
openai.api_key= os.getenv('OPENAI_API_KEY')

from openai import OpenAI

client = OpenAI()

# Function to generate feedback using GPT
def generate_feedback(question, correct_answer, student_answer):
    # Generate feedback using OpenAI GPT

    feedback_prompt = (
        f"The student was asked: '{question}'\n"
        f"The correct answer is: '{correct_answer}'\n"
        f"The student's answer is: '{student_answer}'\n"
        f"Explain why the student's answer is incorrect in 2 sentences. based on the {correct_answer}"
    )

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": feedback_prompt}
        ]
    )

    #feedback = response['choices'][0]['message']['content']
    feedback = response.choices[0].message.content
    return feedback

# Example inputs
question = "What are the different types of crops?"
correct_answer = "The different types of crops include cereals, vegetables, and fruits."
student_answer = "The different types of crops include cereals and fruits"

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.80:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. Feedback:")
    print(feedback)

question = "what does photosynthesis needs?"
correct_answer = "Photosynthesis needs carbon dioxide (CO2) and sunlight"
student_answer = "Photosynthesis needs carbon monoxide (CO) and sunlight"

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.98:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. \n Feedback:")
    print(feedback)

question = "what does photosynthesis needs?"
correct_answer = "Photosynthesis needs carbon dioxide (CO2) and sunlight"
student_answer = "Photosynthesis needs oxygen and carbon dioxide (CO2)"

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.98:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. \n Feedback:")
    print(feedback)

question = "Why is humus important for soil health?"
correct_answer = "Humus is important for soil health because it provides organic matter and nutrients to the soil, improves soil structure and water retention capacity, and enhances microbial activity, which promotes overall plant growth and health."
student_answer = "Humus releases oxygen into the soil, creating a microclimate that requires more frequent watering."

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.98:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. \n Feedback:")
    print(feedback)

question = "For any substance, why does the temperature remain constant during the change of state?"
correct_answer = "The temperature remains constant during a change of state because the heat energy being supplied is used to overcome the forces of attraction between particles, rather than increasing the temperature."
student_answer = "The heat energy supplied during a phase change isn't used to make the substance hotter. It's used to weaken the forces between particles, allowing them to rearrange into a new state."

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.98:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. \n Feedback:")
    print(feedback)

question = "what are oviparous animals?"
correct_answer = "Oviparous animals are animals that lay eggs which later develop into young ones outside the female body."
student_answer = "Animals that reproduce by laying eggs are oviparous. These eggs hatch outside the mother's body."

# Test the model on the example inputs
similarity_score = test_similarity(question, correct_answer, student_answer)
print(f"Similarity score between the correct answer and the student answer: {similarity_score:.4f}")


# Check if the student answer is correct based on the threshold
if similarity_score > 0.80:
    print("Student answer is correct")
else:
    feedback = generate_feedback(question, correct_answer, student_answer)
    print("Student answer is incorrect. \n Feedback:")
    print(feedback)

