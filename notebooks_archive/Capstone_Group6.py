# -*- coding: utf-8 -*-
"""Capstone_Group6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/iisc-ts-group6/capstone/blob/main/Capstone_Group6.ipynb

# Automated answer evaluation

**1. Installing and importing packages**
"""

!pip install openai
!pip install langchain
!pip install langchain-openai
!pip install pypdf
!pip install chromadb
!pip install tiktoken

"""**Imports**"""

import os
import openai
import numpy as np

"""**Authentication for OpenAI API**"""

f = open('/content/openapi_key_team.txt')
api_key = f.read()
os.environ['OPENAI_API_KEY'] = api_key
openai.api_key= os.getenv('OPENAI_API_KEY')

!pip install langchain-community

!pip install langchainhub

!pip install -U accelerate
!pip install -U transformers
!pip install torch

"""**Loading the documents**"""

from IPython import get_ipython

ipython = get_ipython()

def setup():
    #ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2020/05/lakhmir-singh-solutions-for-class-8-science-chapter-9.pdf")
    ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2023/05/ncert-textbook-for-class-8-science-chapter-6.pdf") #reproduction in animals
    ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2023/05/ncert-textbook-for-class-8-science-chapter-2.pdf") #Micro organisms and foe
    ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2023/05/ncert-textbook-for-class-8-science-chapter-5.pdf") #Conservation of Plants and Animals
    ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2023/05/ncert-textbook-for-class-8-science-chapter-7.pdf") #Reaching the Age of Adolescence
    ipython.magic("sx wget https://cdn1.byjus.com/wp-content/uploads/2023/05/ncert-textbook-for-class-8-science-chapter-1.pdf") #Crop production
    ipython.magic("sx wget https://github.com/iisc-ts-group6/capstone/blob/main/data/8/hesc102.pdf") #Cell - Structure and Functions
    print("Setup completed successfully")
    return
#https://ncert.nic.in/textbook.php?hesc1=6-13
setup()

!pip install PyPDF2

from langchain_community.document_loaders import PyPDFLoader


# Load PDF pypdf2
loaders = [

    PyPDFLoader("/content/ncert-textbook-for-class-8-science-chapter-1.pdf"),
    PyPDFLoader("/content/ncert-textbook-for-class-8-science-chapter-2.pdf"),
    PyPDFLoader("/content/ncert-textbook-for-class-8-science-chapter-5.pdf"),
    PyPDFLoader("/content/ncert-textbook-for-class-8-science-chapter-6.pdf"),
    PyPDFLoader("/content/ncert-textbook-for-class-8-science-chapter-7.pdf"),

]
docs = []
for loader in loaders:
    docs.extend(loader.load())

# Read files/documents

from langchain_community.document_loaders import TextLoader


# Create a TextLoader instance
loader = TextLoader("/content/Grade_8.txt")

# Load the text file
docs_text = loader.load()

# Print the loaded documents
for doc in docs_text:
    print(doc)

"""**print them**"""

print(docs[0].page_content)

"""# Splitting of document"""

from langchain_text_splitters import RecursiveCharacterTextSplitter

# Split
#from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 50
)

splits = text_splitter.split_documents(docs)
print(len(splits))
splits

splits = text_splitter.split_documents(docs)
print(len(splits))
splits

"""# Embeddings"""

from langchain_openai import OpenAIEmbeddings
embedding = OpenAIEmbeddings()

embedding

"""#Vectorstores"""

from langchain_community.vectorstores import Chroma # Light-weight and in memory
import os
import shutil

persist_directory = 'docs/chroma/'

# Function to delete the old database directory
def remove_old_database(persist_directory):
    if os.path.exists(persist_directory):
        shutil.rmtree(persist_directory)
        print(f"Removed old database directory: {persist_directory}")
    else:
        print(f"No existing database directory found at: {persist_directory}")

# Remove old database files
remove_old_database(persist_directory)

# Ensure the directory exists and has write permissions
os.makedirs(persist_directory, exist_ok=True)
os.chmod(persist_directory, 0o777)  # Set the directory permissions to be writable

from langchain_community.vectorstores import Chroma # Light-weight and in memory

persist_directory = 'docs/chroma/'
!rm -rf ./docs/chroma  # remove old database files if any

# Assuming 'splits' and 'embedding' are already defined
try:
    vectordb = Chroma.from_documents(
        documents=splits,  # Replace 'splits' with your actual document splits
        embedding=embedding,  # Replace 'embedding' with your actual embedding
        persist_directory=persist_directory  # Save the directory
    )

    # Persist the new database
    vectordb.persist()
    print(f"New vector database initialized and saved to: {persist_directory}")
except Exception as e:
    print(f"An error occurred: {e}")

vectordb.persist() # Let's **save vectordb** so we can use it later!

print(vectordb._collection.count()) # same as number of splits

"""# Retrieval + Question Answering : Connecting with LLMs"""

llm_name = "gpt-3.5-turbo"
print(llm_name)

"""**Vector store-backed retriever**"""

from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model_name=llm_name, temperature=0)

from langchain import hub
prompt = hub.pull("rlm/rag-prompt")
prompt

# Build prompt
from langchain.prompts import PromptTemplate
template = """Use the following pieces of context to answer the question at the end.
explain the answer in 1-2 sentences

If question is not from the uploaded document, just say that you don't know, don't try to make up an answer.
{context}
Question: {question}
Helpful Answer:"""
QA_CHAIN_PROMPT = PromptTemplate(input_variables=["context", "question"],template=template,)

QA_CHAIN_PROMPT

# Run chain
from langchain.chains import RetrievalQA
qa_chain = RetrievalQA.from_chain_type(llm,
                                       retriever=vectordb.as_retriever(search_type="mmr",search_kwargs={"k": 2, "fetch_k":6} ), # "k":2, "fetch_k":3
                                       chain_type_kwargs={"prompt": QA_CHAIN_PROMPT},
                                       return_source_documents=True
                                       )

qa_chain

question = "what does photosynthesis needs?"
result = qa_chain.invoke({"query": question})
result["source_documents"]

result["result"]

#question = "Convert the following temperature to celsius scale: a. 300 K b. 573 K"
question = "who is Prime Minister of INDIA"
result = qa_chain.invoke({"query": question})
result["result"]

"""# Compare two sentences using GPT

"""

from openai import OpenAI

client = OpenAI()
# Function to get the comparison and similarity score from GPT
def compare_sentences(question, student_answer, llm_answer):
    prompt = f"""
    You are an assistant that evaluate a student's answer to a Correct answer.

    question: "{question}"
    Student's answer: "{student_answer}"
    Correct answer: "{llm_answer}"

    for the question the correct answer is the "{llm_answer}"
    based on this fact evaluate the "{student_answer}"  and respond in below format

    Answer:Correct/Incorrect/Partially Correct
    Feedback:
    """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # or "gpt-4" if you have access
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=150,
        temperature=0
    )


    # Print the raw response for debugging
    #print("Raw response:", response)

    #score = float(response.choices[0].message['content'].strip())
    result = response.choices[0].message.content
    print(result)
    # Print the extracted result for debugging


    return response

# Example sentences
question = "what are oviparous animals?"
student_answer = "Animals that reproduce by laying eggs are oviparous. These eggs hatch outside the mother's body."
result = qa_chain.invoke({"query": question})
llm_answer = result["result"]

response1 = compare_sentences(question,student_answer, llm_answer)

# Example sentences
question = "what does photosynthesis needs?"
student_answer = "Photosynthesis needs oxygen , carbon dioxide and sunlight"
result = qa_chain.invoke({"query": question})
llm_answer = result["result"]

response1 = compare_sentences(question,student_answer, llm_answer)

# Example sentences
question = "What are the different types of crops?"
#correct_answer = "The different types of crops include cereals, vegetables, and fruits."
student_answer = "The different types of crops include cereals and fruits"
result = qa_chain.invoke({"query": question})
llm_answer = result["result"]

response1 = compare_sentences(question,student_answer, llm_answer)

# Example sentences
#question = get_random_question()
question = "What are some components or organelles present in the cytoplasm?"
llm_answer = "Some components or organelles present in the cytoplasm include the nucleus, mitochondria, endoplasmic reticulum, and ribosomes."
student_answer = "components or organelles present in the cytoplasm include the nucleus, mitochondria, endoplasmic reticulum."
result = qa_chain.invoke({"query": question})
#llm_answer = result["result"]
print(question)
print(llm_answer)

response1 = compare_sentences(question,student_answer, llm_answer)

"""**Question is from Question bank**"""

# Example sentences
question = get_random_question()
student_answer = "components or organelles present in the cytoplasm include the nucleus, mitochondria, endoplasmic reticulum."
result = qa_chain.invoke({"query": question})
llm_answer = result["result"]
print(question)
print(llm_answer)

response1 = compare_sentences(question,student_answer, llm_answer)

print(result)
src=result["source_documents"]
print(src)

"""# Question random pick"""

!pip install pandas openpyxl

import pandas as pd
import random

# Load the Excel file
file_path = '/content/Question_Bank.xlsx'
df = pd.read_excel(file_path)

df.head()

# Function to get a random question
def get_random_question():
    random_index = random.randint(0, len(df) - 1)
    question = df.iloc[random_index][0]
    return question

# Call the function and store the result in the variable
random = get_random_question()

# Display the question
print(rand)